# -*- coding: utf-8 -*-
"""day24.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FFvga8iA5nsUgp8JoNLBPb988I066qJn
"""

import tensorflow as tf
from datasets import load_dataset
from transformers import (
    BertTokenizer,
    TFBertForSequenceClassification
)

dataset = load_dataset("imdb")

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

def tokenize(batch):
    return tokenizer(
        batch["text"],
        padding="max_length",
        truncation=True,
        max_length=128
    )

dataset = dataset.map(tokenize, batched=True)

train_dataset = dataset["train"].shuffle(1000).select(range(2000))
test_dataset = dataset["test"].select(range(1000))

train_tf = train_dataset.to_tf_dataset(
    columns=["input_ids", "attention_mask"],
    label_cols="label",
    shuffle=True,
    batch_size=8
)

test_tf = test_dataset.to_tf_dataset(
    columns=["input_ids", "attention_mask"],
    label_cols="label",
    shuffle=False,
    batch_size=8
)

import tensorflow as tf
from transformers import TFBertForSequenceClassification

model = TFBertForSequenceClassification.from_pretrained(
    "bert-base-uncased",
    num_labels=2,
    from_pt=True
)

optimizer = tf.keras.optimizers.Adam(
    learning_rate=2e-5
)

loss = tf.keras.losses.SparseCategoricalCrossentropy(
    from_logits=True
)

metrics = ["accuracy"]

model.compile(
    optimizer=optimizer,
    loss=loss,
    metrics=metrics
)

model.fit(
    train_tf,
    validation_data=test_tf,
    epochs=2
)

model.save_pretrained("./bert_tf_finetuned")
tokenizer.save_pretrained("./bert_tf_finetuned")

text = "This movie was really good"

inputs = tokenizer(
    text,
    return_tensors="tf",
    truncation=True,
    padding=True
)

outputs = model(inputs)
prediction = tf.argmax(outputs.logits, axis=1).numpy()[0]

print("Positive" if prediction == 1 else "Negative")

"""# Project 2: Object Detection System using YOLO"""









pip install tensorflow opencv-python numpy

def load_classes(class_file):
    with open(class_file, "r") as f:
        return [line.strip() for line in f.readlines()]

classes = load_classes("coco.names")

def load_classes(class_file):
    with open(class_file, "r") as f:
        return [line.strip() for line in f.readlines()]

classes = load_classes("coco.names")

import tensorflow as tf
import cv2
import numpy as np

# Load YOLO model
net = cv2.dnn.readNetFromDarknet(
    "yolov3.cfg",
    "yolov3.weights"
)

# OpenCV DNN backend
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

image = cv2.imread("image.jpg")
h, w = image.shape[:2]

# Convert image to blob
blob = cv2.dnn.blobFromImage(
    image,
    1/255.0,
    (416, 416),
    swapRB=True,
    crop=False
)

net.setInput(blob)

layer_names = net.getLayerNames()
output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]

detections = net.forward(output_layers)

boxes = []
confidences = []
class_ids = []

for output in detections:
    for detection in output:
        scores = detection[5:]
        class_id = np.argmax(scores)
        confidence = scores[class_id]

        if confidence > 0.5:
            center_x = int(detection[0] * w)
            center_y = int(detection[1] * h)
            bw = int(detection[2] * w)
            bh = int(detection[3] * h)

            x = int(center_x - bw / 2)
            y = int(center_y - bh / 2)

            boxes.append([x, y, bw, bh])
            confidences.append(float(confidence))
            class_ids.append(class_id)

indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

# Draw boxes
for i in indexes.flatten():
    x, y, bw, bh = boxes[i]
    label = classes[class_ids[i]]

    cv2.rectangle(image, (x, y), (x + bw, y + bh), (0, 255, 0), 2)
    cv2.putText(image, label, (x, y - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

cv2.imshow("YOLO Detection", image)
cv2.waitKey(0)
cv2.destroyAllWindows()

cap = cv2.VideoCapture("video.mp4")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    h, w = frame.shape[:2]

    blob = cv2.dnn.blobFromImage(
        frame, 1/255.0, (416, 416), swapRB=True, crop=False
    )
    net.setInput(blob)
    outputs = net.forward(output_layers)

    boxes, confidences, class_ids = [], [], []

    for output in outputs:
        for detection in output:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            if confidence > 0.5:
                center_x = int(detection[0] * w)
                center_y = int(detection[1] * h)
                bw = int(detection[2] * w)
                bh = int(detection[3] * h)

                x = int(center_x - bw / 2)
                y = int(center_y - bh / 2)

                boxes.append([x, y, bw, bh])
                confidences.append(float(confidence))
                class_ids.append(class_id)

    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

    for i in indexes.flatten():
        x, y, bw, bh = boxes[i]
        label = classes[class_ids[i]]

        cv2.rectangle(frame, (x, y), (x + bw, y + bh), (255, 0, 0), 2)
        cv2.putText(frame, label, (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    cv2.imshow("YOLO Video", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

